import gradio as gr
import numpy as np
import soundfile as sf
import shutil
import os
import sys
import json
import contextlib
from io import StringIO

# å¼•å…¥Agentç›¸å…³æ¨¡å—
from react_agent.LLM import RequestLLM
from react_agent.agent import ReactAgent
from react_agent.tools import tools_registry
import voice
import tools  # å¯¼å…¥toolsä»¥æ³¨å†Œå·¥å…·

# å›ºå®šçš„æ–‡ä»¶å
FIXED_FLAC_FILE = "current_recording.flac"
TARGET_FLAC_FILE = "Recording.flac"

# åˆå§‹åŒ–Agent
print("æ­£åœ¨åˆå§‹åŒ–Agent...")
try:
    llm = RequestLLM(base_url="https://api.deepseek.com/v1", model_name="deepseek-chat")
    agent = ReactAgent(llm)

    # æ³¨å†Œå·¥å…·
    for name, cls in tools_registry.items():
        agent.register_tool(name, cls)

    # æ›´æ–°ç³»ç»Ÿprompt
    agent.update_system_message()

    # åŠ è½½é…ç½®
    try:
        with open("config.json", "r") as config_file:
            config_data = json.load(config_file)
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        config_data = {}
    print("Agentåˆå§‹åŒ–å®Œæˆ")
except Exception as e:
    print(f"Agentåˆå§‹åŒ–å¤±è´¥: {e}")
    agent = None

@contextlib.contextmanager
def capture_stdout():
    new_out = StringIO()
    old_out = sys.stdout
    try:
        sys.stdout = new_out
        yield new_out
    finally:
        sys.stdout = old_out

def save_and_process_audio(audio):
    """å½•éŸ³å®Œæˆåè‡ªåŠ¨ä¿å­˜ä¸ºFLACæ–‡ä»¶"""
    if audio is None:
        return "âŒ æœªæ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥", None
    
    sample_rate, audio_data = audio
    
    try:
        # ä¿å­˜ä¸ºå›ºå®šFLACæ–‡ä»¶ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰
        sf.write(file=FIXED_FLAC_FILE,
                 data=audio_data,
                 samplerate=sample_rate,
                 format='FLAC',
                 subtype='PCM_16')
        
        duration = len(audio_data) / sample_rate
        message = f"âœ… å½•éŸ³å·²ä¿å­˜: {FIXED_FLAC_FILE}\næ—¶é•¿: {duration:.1f}ç§’, é‡‡æ ·ç‡: {sample_rate}Hz"
        
        return message, FIXED_FLAC_FILE
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}", None

def copy_to_recording():
    """å¤åˆ¶æ–‡ä»¶åˆ°å½“å‰ç›®å½•çš„Recording.flac"""
    if not os.path.exists(FIXED_FLAC_FILE):
        return f"âŒ æ‰¾ä¸åˆ° {FIXED_FLAC_FILE}ï¼Œè¯·å…ˆå½•åˆ¶éŸ³é¢‘"
    
    try:
        # å¤åˆ¶æ–‡ä»¶
        shutil.copy2(FIXED_FLAC_FILE, TARGET_FLAC_FILE)
        
        # éªŒè¯å¤åˆ¶ç»“æœ
        if os.path.exists(TARGET_FLAC_FILE):
            file_size = os.path.getsize(TARGET_FLAC_FILE) / 1024
            return f"âœ… å¤åˆ¶æˆåŠŸ: {TARGET_FLAC_FILE} ({file_size:.1f}KB)"
        else:
            return "âŒ å¤åˆ¶å¤±è´¥ï¼šç›®æ ‡æ–‡ä»¶æœªåˆ›å»º"
    except Exception as e:
        return f"âŒ å¤åˆ¶å¤±è´¥: {str(e)}"

def process_text_interaction(text, history):
    """å¤„ç†æ–‡å­—äº¤äº’"""
    if not text:
        return "", history
    
    history = history or []
    history.append({"role": "user", "content": text})
    
    if agent is None:
        history.append({"role": "assistant", "content": "âŒ Agentæœªåˆå§‹åŒ–æˆåŠŸï¼Œæ— æ³•å¤„ç†æŒ‡ä»¤ã€‚"})
        return "", history

    with capture_stdout() as out:
        try:
            print(f"<USER>: {text}")
            agent.chat(text)
        except Exception as e:
            print(f"Error during chat: {e}")
    
    output = out.getvalue()
    history.append({"role": "assistant", "content": output})
    return "", history

def process_voice_interaction(history):
    """å¤„ç†è¯­éŸ³äº¤äº’ï¼šå¤åˆ¶æ–‡ä»¶ -> è¯†åˆ« -> Agentå¯¹è¯"""
    history = history or []

    # 1. å¤åˆ¶æ–‡ä»¶
    copy_msg = copy_to_recording()
    if "âŒ" in copy_msg:
        history.append({"role": "assistant", "content": copy_msg})
        return history, copy_msg

    # 2. è¯­éŸ³è¯†åˆ«
    try:
        # voice.record_auto() è¯»å– Recording.flac å¹¶è¿”å›æ–‡æœ¬
        user_input = voice.record_auto()
    except Exception as e:
        msg = f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}"
        history.append({"role": "assistant", "content": msg})
        return history, msg

    if not user_input:
        return history, "è¯­éŸ³è¯†åˆ«ç»“æœä¸ºç©º"

    # 3. Agentå¯¹è¯
    history.append({"role": "user", "content": f"[è¯­éŸ³] {user_input}"})

    if agent is None:
        history.append({"role": "assistant", "content": "âŒ Agentæœªåˆå§‹åŒ–æˆåŠŸï¼Œæ— æ³•å¤„ç†æŒ‡ä»¤ã€‚"})
        return history, "Agentæœªåˆå§‹åŒ–"

    with capture_stdout() as out:
        try:
            agent.chat(user_input)
        except Exception as e:
            print(f"Error during chat: {e}")
            
    output = out.getvalue()
    history.append({"role": "assistant", "content": output})
    
    return history, f"è¯­éŸ³æŒ‡ä»¤å·²æ‰§è¡Œ: {user_input}"

# åˆ›å»ºäº¤äº’ç•Œé¢
with gr.Blocks(title="Jetson AI äº¤äº’ç»ˆç«¯", theme=gr.themes.Soft()) as demo:
    gr.Markdown("## ğŸ¤– Jetson AI äº¤äº’ç»ˆç«¯")
    
    # 1. æ‘„åƒå¤´ç”»é¢ (é¢„ç•™)
    with gr.Row():
        camera_display = gr.Image(label="æ‘„åƒå¤´ç”»é¢", height=400, interactive=False, sources=None)

    # èŠå¤©è®°å½•æ˜¾ç¤º
    chatbot = gr.Chatbot(label="äº¤äº’è®°å½•", height=500)

    # 2. äº¤äº’åŒºåŸŸ
    with gr.Row():
        # æ–‡å­—äº¤äº’åŒºåŸŸ
        with gr.Column():
            gr.Markdown("### ğŸ“ æ–‡å­—äº¤äº’")
            text_input = gr.Textbox(label="è¾“å…¥æŒ‡ä»¤", placeholder="è¯·è¾“å…¥æ–‡å­—å¹¶å›è½¦...")
            text_button = gr.Button("å‘é€æ–‡å­—")
            
            text_input.submit(process_text_interaction, inputs=[text_input, chatbot], outputs=[text_input, chatbot])
            text_button.click(process_text_interaction, inputs=[text_input, chatbot], outputs=[text_input, chatbot])

        # è¯­éŸ³äº¤äº’åŒºåŸŸ
        with gr.Column():
            gr.Markdown("### ğŸ—£ï¸ è¯­éŸ³äº¤äº’")
            audio_input = gr.Audio(
                sources=["microphone"],
                type="numpy",
                label="è¯­éŸ³å½•å…¥",
                format="wav",
                interactive=True
            )
            status_display = gr.Textbox(label="çŠ¶æ€", value="ç­‰å¾…å½•éŸ³...", lines=2)
            # éšè—çš„éŸ³é¢‘æ’­æ”¾ç»„ä»¶
            audio_output = gr.Audio(label="å½•éŸ³å›æ”¾", visible=False, interactive=False)
            
            voice_button = gr.Button("å‘é€è¯­éŸ³ (å¤åˆ¶åˆ°Recording.flac)", variant="primary")
            
            # å½•éŸ³å®Œæˆåè‡ªåŠ¨ä¿å­˜
            audio_input.change(
                fn=save_and_process_audio,
                inputs=[audio_input],
                outputs=[status_display, audio_output]
            )
            
            # ç‚¹å‡»æŒ‰é’®æ‰§è¡Œè¯­éŸ³æµç¨‹
            voice_button.click(
                fn=process_voice_interaction,
                inputs=[chatbot],
                outputs=[chatbot, status_display]
            )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    print("å¯åŠ¨Jetson AI äº¤äº’ç»ˆç«¯...")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
